{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8f4f85",
   "metadata": {},
   "source": [
    "# 机器学习练习-集成学习\n",
    "代码更新地址：https://github.com/fengdu78/WZU-machine-learning-course\n",
    "\n",
    "\n",
    "代码修改并注释：黄海广，haiguang2000@wzu.edu.cn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3257f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc304344",
   "metadata": {},
   "source": [
    "## 生成数据\n",
    "生成12000行的数据，训练集和测试集按照3:1划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebd8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n",
    "data, target = make_hastie_10_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cca920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将-1替换为0\n",
    "target[target == -1] = 0\n",
    "# 确保数据类型为整数\n",
    "target = target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dfeb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 10), (3000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=123)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ac5c7",
   "metadata": {},
   "source": [
    "## 模型对比\n",
    "对比六大模型，都使用默认参数，因为数据是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f808ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48911111 (+/- 0.01),耗时0.04秒。模型名称[Logistic Regression]\n",
      "Accuracy: 0.88988889 (+/- 0.01),耗时26.34秒。模型名称[Random Forest]\n",
      "Accuracy: 0.87944444 (+/- 0.01),耗时4.84秒。模型名称[AdaBoost]\n",
      "Accuracy: 0.91866667 (+/- 0.00),耗时33.51秒。模型名称[GBDT]\n",
      "Accuracy: 0.92222222 (+/- 0.01),耗时1.67秒。模型名称[XGBoost]\n",
      "[LightGBM] [Info] Number of positive: 3606, number of negative: 3594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 7200, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500833 -> initscore=0.003333\n",
      "[LightGBM] [Info] Start training from score 0.003333\n",
      "[LightGBM] [Info] Number of positive: 3606, number of negative: 3594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 7200, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500833 -> initscore=0.003333\n",
      "[LightGBM] [Info] Start training from score 0.003333\n",
      "[LightGBM] [Info] Number of positive: 3606, number of negative: 3594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 7200, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500833 -> initscore=0.003333\n",
      "[LightGBM] [Info] Start training from score 0.003333\n",
      "[LightGBM] [Info] Number of positive: 3605, number of negative: 3595\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 7200, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500694 -> initscore=0.002778\n",
      "[LightGBM] [Info] Start training from score 0.002778\n",
      "[LightGBM] [Info] Number of positive: 3605, number of negative: 3595\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 7200, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500694 -> initscore=0.002778\n",
      "[LightGBM] [Info] Start training from score 0.002778\n",
      "Accuracy: 0.93088889 (+/- 0.01),耗时2.97秒。模型名称[LightGBM]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = AdaBoostClassifier()\n",
    "clf4 = GradientBoostingClassifier()\n",
    "clf5 = XGBClassifier()\n",
    "clf6 = LGBMClassifier()\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6], [\n",
    "        'Logistic Regression', 'Random Forest', 'AdaBoost', 'GBDT', 'XGBoost',\n",
    "        'LightGBM'\n",
    "]):\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    end = time.time()\n",
    "    running_time = end - start\n",
    "    print(\"Accuracy: %0.8f (+/- %0.2f),耗时%0.2f秒。模型名称[%s]\" %\n",
    "          (scores.mean(), scores.std(), running_time, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa60220",
   "metadata": {},
   "source": [
    "对比了六大模型，可以看出，逻辑回归速度最快，但准确率最低。\n",
    "而LightGBM，速度快，而且准确率最高，所以，现在处理结构化数据的时候，大部分都是用LightGBM算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e7313",
   "metadata": {},
   "source": [
    "## XGBoost的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5b733",
   "metadata": {},
   "source": [
    "### 1.原生XGBoost的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d20084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#记录程序运行时间\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#xgb矩阵赋值\n",
    "xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "##参数\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "#     'silent': 1,  #设置成1则没有运行信息输出，最好是设置为0.\n",
    "    #'nthread':7,# cpu 线程数 默认最大\n",
    "    'eta': 0.007,  # 如同学习率\n",
    "    'min_child_weight': 3,\n",
    "    # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "    #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "    #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "    'max_depth': 6,  # 构建树的深度，越大越容易过拟合\n",
    "    'gamma': 0.1,  # 树的叶子节点上作进一步分区所需的最小损失减少,越大越保守，一般0.1、0.2这样子。\n",
    "    'subsample': 0.7,  # 随机采样训练样本\n",
    "    'colsample_bytree': 0.7,  # 生成树时进行的列采样 \n",
    "    'lambda': 2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    #'alpha':0, # L1 正则项参数\n",
    "    #'scale_pos_weight':1, #如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。\n",
    "    #'objective': 'multi:softmax', #多分类的问题\n",
    "    #'num_class':10, # 类别数，多分类与 multisoftmax 并用\n",
    "    'seed': 1000,  #随机种子\n",
    "    #'eval_metric': 'auc'\n",
    "}\n",
    "plst = list(params.items())\n",
    "num_rounds = 500  # 迭代次数\n",
    "watchlist = [(xgb_train, 'train'), (xgb_test, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7421bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.49936\tval-rmse:0.49945\n",
      "[1]\ttrain-rmse:0.49872\tval-rmse:0.49889\n",
      "[2]\ttrain-rmse:0.49812\tval-rmse:0.49835\n",
      "[3]\ttrain-rmse:0.49748\tval-rmse:0.49781\n",
      "[4]\ttrain-rmse:0.49684\tval-rmse:0.49727\n",
      "[5]\ttrain-rmse:0.49621\tval-rmse:0.49671\n",
      "[6]\ttrain-rmse:0.49558\tval-rmse:0.49614\n",
      "[7]\ttrain-rmse:0.49493\tval-rmse:0.49559\n",
      "[8]\ttrain-rmse:0.49432\tval-rmse:0.49504\n",
      "[9]\ttrain-rmse:0.49372\tval-rmse:0.49445\n",
      "[10]\ttrain-rmse:0.49310\tval-rmse:0.49390\n",
      "[11]\ttrain-rmse:0.49250\tval-rmse:0.49340\n",
      "[12]\ttrain-rmse:0.49189\tval-rmse:0.49287\n",
      "[13]\ttrain-rmse:0.49129\tval-rmse:0.49230\n",
      "[14]\ttrain-rmse:0.49069\tval-rmse:0.49177\n",
      "[15]\ttrain-rmse:0.49009\tval-rmse:0.49124\n",
      "[16]\ttrain-rmse:0.48948\tval-rmse:0.49072\n",
      "[17]\ttrain-rmse:0.48890\tval-rmse:0.49017\n",
      "[18]\ttrain-rmse:0.48832\tval-rmse:0.48965\n",
      "[19]\ttrain-rmse:0.48774\tval-rmse:0.48911\n",
      "[20]\ttrain-rmse:0.48715\tval-rmse:0.48858\n",
      "[21]\ttrain-rmse:0.48655\tval-rmse:0.48811\n",
      "[22]\ttrain-rmse:0.48595\tval-rmse:0.48759\n",
      "[23]\ttrain-rmse:0.48535\tval-rmse:0.48708\n",
      "[24]\ttrain-rmse:0.48477\tval-rmse:0.48654\n",
      "[25]\ttrain-rmse:0.48419\tval-rmse:0.48602\n",
      "[26]\ttrain-rmse:0.48359\tval-rmse:0.48551\n",
      "[27]\ttrain-rmse:0.48300\tval-rmse:0.48499\n",
      "[28]\ttrain-rmse:0.48240\tval-rmse:0.48450\n",
      "[29]\ttrain-rmse:0.48183\tval-rmse:0.48400\n",
      "[30]\ttrain-rmse:0.48127\tval-rmse:0.48355\n",
      "[31]\ttrain-rmse:0.48072\tval-rmse:0.48309\n",
      "[32]\ttrain-rmse:0.48015\tval-rmse:0.48256\n",
      "[33]\ttrain-rmse:0.47958\tval-rmse:0.48207\n",
      "[34]\ttrain-rmse:0.47902\tval-rmse:0.48157\n",
      "[35]\ttrain-rmse:0.47845\tval-rmse:0.48109\n",
      "[36]\ttrain-rmse:0.47789\tval-rmse:0.48059\n",
      "[37]\ttrain-rmse:0.47729\tval-rmse:0.48013\n",
      "[38]\ttrain-rmse:0.47673\tval-rmse:0.47962\n",
      "[39]\ttrain-rmse:0.47617\tval-rmse:0.47915\n",
      "[40]\ttrain-rmse:0.47562\tval-rmse:0.47862\n",
      "[41]\ttrain-rmse:0.47507\tval-rmse:0.47813\n",
      "[42]\ttrain-rmse:0.47448\tval-rmse:0.47762\n",
      "[43]\ttrain-rmse:0.47391\tval-rmse:0.47706\n",
      "[44]\ttrain-rmse:0.47335\tval-rmse:0.47658\n",
      "[45]\ttrain-rmse:0.47279\tval-rmse:0.47606\n",
      "[46]\ttrain-rmse:0.47220\tval-rmse:0.47556\n",
      "[47]\ttrain-rmse:0.47166\tval-rmse:0.47509\n",
      "[48]\ttrain-rmse:0.47110\tval-rmse:0.47454\n",
      "[49]\ttrain-rmse:0.47053\tval-rmse:0.47402\n",
      "[50]\ttrain-rmse:0.46996\tval-rmse:0.47350\n",
      "[51]\ttrain-rmse:0.46940\tval-rmse:0.47305\n",
      "[52]\ttrain-rmse:0.46886\tval-rmse:0.47260\n",
      "[53]\ttrain-rmse:0.46832\tval-rmse:0.47211\n",
      "[54]\ttrain-rmse:0.46777\tval-rmse:0.47157\n",
      "[55]\ttrain-rmse:0.46723\tval-rmse:0.47109\n",
      "[56]\ttrain-rmse:0.46668\tval-rmse:0.47063\n",
      "[57]\ttrain-rmse:0.46618\tval-rmse:0.47021\n",
      "[58]\ttrain-rmse:0.46565\tval-rmse:0.46975\n",
      "[59]\ttrain-rmse:0.46513\tval-rmse:0.46930\n",
      "[60]\ttrain-rmse:0.46458\tval-rmse:0.46882\n",
      "[61]\ttrain-rmse:0.46402\tval-rmse:0.46831\n",
      "[62]\ttrain-rmse:0.46347\tval-rmse:0.46780\n",
      "[63]\ttrain-rmse:0.46295\tval-rmse:0.46733\n",
      "[64]\ttrain-rmse:0.46242\tval-rmse:0.46687\n",
      "[65]\ttrain-rmse:0.46188\tval-rmse:0.46640\n",
      "[66]\ttrain-rmse:0.46134\tval-rmse:0.46596\n",
      "[67]\ttrain-rmse:0.46078\tval-rmse:0.46546\n",
      "[68]\ttrain-rmse:0.46026\tval-rmse:0.46498\n",
      "[69]\ttrain-rmse:0.45973\tval-rmse:0.46450\n",
      "[70]\ttrain-rmse:0.45919\tval-rmse:0.46403\n",
      "[71]\ttrain-rmse:0.45864\tval-rmse:0.46358\n",
      "[72]\ttrain-rmse:0.45813\tval-rmse:0.46313\n",
      "[73]\ttrain-rmse:0.45760\tval-rmse:0.46265\n",
      "[74]\ttrain-rmse:0.45707\tval-rmse:0.46219\n",
      "[75]\ttrain-rmse:0.45655\tval-rmse:0.46174\n",
      "[76]\ttrain-rmse:0.45605\tval-rmse:0.46130\n",
      "[77]\ttrain-rmse:0.45551\tval-rmse:0.46085\n",
      "[78]\ttrain-rmse:0.45499\tval-rmse:0.46037\n",
      "[79]\ttrain-rmse:0.45444\tval-rmse:0.45993\n",
      "[80]\ttrain-rmse:0.45391\tval-rmse:0.45948\n",
      "[81]\ttrain-rmse:0.45339\tval-rmse:0.45899\n",
      "[82]\ttrain-rmse:0.45289\tval-rmse:0.45857\n",
      "[83]\ttrain-rmse:0.45236\tval-rmse:0.45811\n",
      "[84]\ttrain-rmse:0.45184\tval-rmse:0.45766\n",
      "[85]\ttrain-rmse:0.45133\tval-rmse:0.45722\n",
      "[86]\ttrain-rmse:0.45084\tval-rmse:0.45677\n",
      "[87]\ttrain-rmse:0.45033\tval-rmse:0.45637\n",
      "[88]\ttrain-rmse:0.44983\tval-rmse:0.45590\n",
      "[89]\ttrain-rmse:0.44933\tval-rmse:0.45547\n",
      "[90]\ttrain-rmse:0.44882\tval-rmse:0.45501\n",
      "[91]\ttrain-rmse:0.44830\tval-rmse:0.45454\n",
      "[92]\ttrain-rmse:0.44780\tval-rmse:0.45413\n",
      "[93]\ttrain-rmse:0.44730\tval-rmse:0.45370\n",
      "[94]\ttrain-rmse:0.44681\tval-rmse:0.45328\n",
      "[95]\ttrain-rmse:0.44629\tval-rmse:0.45282\n",
      "[96]\ttrain-rmse:0.44581\tval-rmse:0.45240\n",
      "[97]\ttrain-rmse:0.44533\tval-rmse:0.45198\n",
      "[98]\ttrain-rmse:0.44483\tval-rmse:0.45157\n",
      "[99]\ttrain-rmse:0.44434\tval-rmse:0.45112\n",
      "[100]\ttrain-rmse:0.44388\tval-rmse:0.45073\n",
      "[101]\ttrain-rmse:0.44339\tval-rmse:0.45030\n",
      "[102]\ttrain-rmse:0.44290\tval-rmse:0.44989\n",
      "[103]\ttrain-rmse:0.44243\tval-rmse:0.44949\n",
      "[104]\ttrain-rmse:0.44192\tval-rmse:0.44902\n",
      "[105]\ttrain-rmse:0.44144\tval-rmse:0.44859\n",
      "[106]\ttrain-rmse:0.44095\tval-rmse:0.44819\n",
      "[107]\ttrain-rmse:0.44044\tval-rmse:0.44773\n",
      "[108]\ttrain-rmse:0.43997\tval-rmse:0.44733\n",
      "[109]\ttrain-rmse:0.43951\tval-rmse:0.44693\n",
      "[110]\ttrain-rmse:0.43903\tval-rmse:0.44651\n",
      "[111]\ttrain-rmse:0.43858\tval-rmse:0.44614\n",
      "[112]\ttrain-rmse:0.43810\tval-rmse:0.44569\n",
      "[113]\ttrain-rmse:0.43761\tval-rmse:0.44526\n",
      "[114]\ttrain-rmse:0.43715\tval-rmse:0.44485\n",
      "[115]\ttrain-rmse:0.43669\tval-rmse:0.44442\n",
      "[116]\ttrain-rmse:0.43623\tval-rmse:0.44399\n",
      "[117]\ttrain-rmse:0.43577\tval-rmse:0.44360\n",
      "[118]\ttrain-rmse:0.43530\tval-rmse:0.44319\n",
      "[119]\ttrain-rmse:0.43483\tval-rmse:0.44279\n",
      "[120]\ttrain-rmse:0.43437\tval-rmse:0.44238\n",
      "[121]\ttrain-rmse:0.43390\tval-rmse:0.44196\n",
      "[122]\ttrain-rmse:0.43344\tval-rmse:0.44158\n",
      "[123]\ttrain-rmse:0.43297\tval-rmse:0.44120\n",
      "[124]\ttrain-rmse:0.43250\tval-rmse:0.44079\n",
      "[125]\ttrain-rmse:0.43204\tval-rmse:0.44038\n",
      "[126]\ttrain-rmse:0.43156\tval-rmse:0.43999\n",
      "[127]\ttrain-rmse:0.43109\tval-rmse:0.43959\n",
      "[128]\ttrain-rmse:0.43062\tval-rmse:0.43919\n",
      "[129]\ttrain-rmse:0.43016\tval-rmse:0.43878\n",
      "[130]\ttrain-rmse:0.42970\tval-rmse:0.43837\n",
      "[131]\ttrain-rmse:0.42924\tval-rmse:0.43797\n",
      "[132]\ttrain-rmse:0.42881\tval-rmse:0.43758\n",
      "[133]\ttrain-rmse:0.42837\tval-rmse:0.43720\n",
      "[134]\ttrain-rmse:0.42794\tval-rmse:0.43680\n",
      "[135]\ttrain-rmse:0.42748\tval-rmse:0.43641\n",
      "[136]\ttrain-rmse:0.42701\tval-rmse:0.43601\n",
      "[137]\ttrain-rmse:0.42658\tval-rmse:0.43568\n",
      "[138]\ttrain-rmse:0.42612\tval-rmse:0.43530\n",
      "[139]\ttrain-rmse:0.42567\tval-rmse:0.43492\n",
      "[140]\ttrain-rmse:0.42522\tval-rmse:0.43451\n",
      "[141]\ttrain-rmse:0.42480\tval-rmse:0.43412\n",
      "[142]\ttrain-rmse:0.42436\tval-rmse:0.43377\n",
      "[143]\ttrain-rmse:0.42392\tval-rmse:0.43339\n",
      "[144]\ttrain-rmse:0.42348\tval-rmse:0.43300\n",
      "[145]\ttrain-rmse:0.42305\tval-rmse:0.43263\n",
      "[146]\ttrain-rmse:0.42262\tval-rmse:0.43223\n",
      "[147]\ttrain-rmse:0.42217\tval-rmse:0.43184\n",
      "[148]\ttrain-rmse:0.42172\tval-rmse:0.43140\n",
      "[149]\ttrain-rmse:0.42129\tval-rmse:0.43104\n",
      "[150]\ttrain-rmse:0.42085\tval-rmse:0.43064\n",
      "[151]\ttrain-rmse:0.42041\tval-rmse:0.43026\n",
      "[152]\ttrain-rmse:0.41998\tval-rmse:0.42986\n",
      "[153]\ttrain-rmse:0.41956\tval-rmse:0.42953\n",
      "[154]\ttrain-rmse:0.41911\tval-rmse:0.42915\n",
      "[155]\ttrain-rmse:0.41870\tval-rmse:0.42880\n",
      "[156]\ttrain-rmse:0.41826\tval-rmse:0.42843\n",
      "[157]\ttrain-rmse:0.41782\tval-rmse:0.42805\n",
      "[158]\ttrain-rmse:0.41738\tval-rmse:0.42768\n",
      "[159]\ttrain-rmse:0.41694\tval-rmse:0.42732\n",
      "[160]\ttrain-rmse:0.41651\tval-rmse:0.42698\n",
      "[161]\ttrain-rmse:0.41610\tval-rmse:0.42663\n",
      "[162]\ttrain-rmse:0.41568\tval-rmse:0.42625\n",
      "[163]\ttrain-rmse:0.41528\tval-rmse:0.42591\n",
      "[164]\ttrain-rmse:0.41485\tval-rmse:0.42557\n",
      "[165]\ttrain-rmse:0.41442\tval-rmse:0.42523\n",
      "[166]\ttrain-rmse:0.41399\tval-rmse:0.42484\n",
      "[167]\ttrain-rmse:0.41355\tval-rmse:0.42444\n",
      "[168]\ttrain-rmse:0.41310\tval-rmse:0.42407\n",
      "[169]\ttrain-rmse:0.41270\tval-rmse:0.42375\n",
      "[170]\ttrain-rmse:0.41231\tval-rmse:0.42344\n",
      "[171]\ttrain-rmse:0.41187\tval-rmse:0.42306\n",
      "[172]\ttrain-rmse:0.41144\tval-rmse:0.42273\n",
      "[173]\ttrain-rmse:0.41104\tval-rmse:0.42237\n",
      "[174]\ttrain-rmse:0.41062\tval-rmse:0.42198\n",
      "[175]\ttrain-rmse:0.41019\tval-rmse:0.42162\n",
      "[176]\ttrain-rmse:0.40977\tval-rmse:0.42132\n",
      "[177]\ttrain-rmse:0.40934\tval-rmse:0.42094\n",
      "[178]\ttrain-rmse:0.40894\tval-rmse:0.42058\n",
      "[179]\ttrain-rmse:0.40853\tval-rmse:0.42022\n",
      "[180]\ttrain-rmse:0.40811\tval-rmse:0.41988\n",
      "[181]\ttrain-rmse:0.40769\tval-rmse:0.41954\n",
      "[182]\ttrain-rmse:0.40730\tval-rmse:0.41920\n",
      "[183]\ttrain-rmse:0.40691\tval-rmse:0.41885\n",
      "[184]\ttrain-rmse:0.40653\tval-rmse:0.41851\n",
      "[185]\ttrain-rmse:0.40613\tval-rmse:0.41820\n",
      "[186]\ttrain-rmse:0.40573\tval-rmse:0.41787\n",
      "[187]\ttrain-rmse:0.40536\tval-rmse:0.41753\n",
      "[188]\ttrain-rmse:0.40496\tval-rmse:0.41721\n",
      "[189]\ttrain-rmse:0.40457\tval-rmse:0.41688\n",
      "[190]\ttrain-rmse:0.40419\tval-rmse:0.41655\n",
      "[191]\ttrain-rmse:0.40376\tval-rmse:0.41617\n",
      "[192]\ttrain-rmse:0.40338\tval-rmse:0.41580\n",
      "[193]\ttrain-rmse:0.40299\tval-rmse:0.41548\n",
      "[194]\ttrain-rmse:0.40260\tval-rmse:0.41513\n",
      "[195]\ttrain-rmse:0.40224\tval-rmse:0.41479\n",
      "[196]\ttrain-rmse:0.40184\tval-rmse:0.41444\n",
      "[197]\ttrain-rmse:0.40146\tval-rmse:0.41415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198]\ttrain-rmse:0.40105\tval-rmse:0.41384\n",
      "[199]\ttrain-rmse:0.40067\tval-rmse:0.41354\n",
      "[200]\ttrain-rmse:0.40030\tval-rmse:0.41323\n",
      "[201]\ttrain-rmse:0.39993\tval-rmse:0.41292\n",
      "[202]\ttrain-rmse:0.39955\tval-rmse:0.41260\n",
      "[203]\ttrain-rmse:0.39918\tval-rmse:0.41229\n",
      "[204]\ttrain-rmse:0.39881\tval-rmse:0.41201\n",
      "[205]\ttrain-rmse:0.39844\tval-rmse:0.41165\n",
      "[206]\ttrain-rmse:0.39809\tval-rmse:0.41132\n",
      "[207]\ttrain-rmse:0.39772\tval-rmse:0.41098\n",
      "[208]\ttrain-rmse:0.39732\tval-rmse:0.41064\n",
      "[209]\ttrain-rmse:0.39696\tval-rmse:0.41033\n",
      "[210]\ttrain-rmse:0.39661\tval-rmse:0.40999\n",
      "[211]\ttrain-rmse:0.39623\tval-rmse:0.40967\n",
      "[212]\ttrain-rmse:0.39584\tval-rmse:0.40935\n",
      "[213]\ttrain-rmse:0.39545\tval-rmse:0.40902\n",
      "[214]\ttrain-rmse:0.39507\tval-rmse:0.40868\n",
      "[215]\ttrain-rmse:0.39468\tval-rmse:0.40835\n",
      "[216]\ttrain-rmse:0.39432\tval-rmse:0.40806\n",
      "[217]\ttrain-rmse:0.39393\tval-rmse:0.40773\n",
      "[218]\ttrain-rmse:0.39357\tval-rmse:0.40746\n",
      "[219]\ttrain-rmse:0.39320\tval-rmse:0.40717\n",
      "[220]\ttrain-rmse:0.39280\tval-rmse:0.40686\n",
      "[221]\ttrain-rmse:0.39241\tval-rmse:0.40655\n",
      "[222]\ttrain-rmse:0.39202\tval-rmse:0.40622\n",
      "[223]\ttrain-rmse:0.39164\tval-rmse:0.40588\n",
      "[224]\ttrain-rmse:0.39127\tval-rmse:0.40560\n",
      "[225]\ttrain-rmse:0.39091\tval-rmse:0.40529\n",
      "[226]\ttrain-rmse:0.39057\tval-rmse:0.40502\n",
      "[227]\ttrain-rmse:0.39018\tval-rmse:0.40471\n",
      "[228]\ttrain-rmse:0.38984\tval-rmse:0.40442\n",
      "[229]\ttrain-rmse:0.38945\tval-rmse:0.40410\n",
      "[230]\ttrain-rmse:0.38908\tval-rmse:0.40382\n",
      "[231]\ttrain-rmse:0.38874\tval-rmse:0.40354\n",
      "[232]\ttrain-rmse:0.38838\tval-rmse:0.40324\n",
      "[233]\ttrain-rmse:0.38803\tval-rmse:0.40297\n",
      "[234]\ttrain-rmse:0.38766\tval-rmse:0.40267\n",
      "[235]\ttrain-rmse:0.38730\tval-rmse:0.40234\n",
      "[236]\ttrain-rmse:0.38697\tval-rmse:0.40204\n",
      "[237]\ttrain-rmse:0.38660\tval-rmse:0.40171\n",
      "[238]\ttrain-rmse:0.38625\tval-rmse:0.40142\n",
      "[239]\ttrain-rmse:0.38591\tval-rmse:0.40112\n",
      "[240]\ttrain-rmse:0.38557\tval-rmse:0.40082\n",
      "[241]\ttrain-rmse:0.38523\tval-rmse:0.40055\n",
      "[242]\ttrain-rmse:0.38490\tval-rmse:0.40025\n",
      "[243]\ttrain-rmse:0.38454\tval-rmse:0.39998\n",
      "[244]\ttrain-rmse:0.38420\tval-rmse:0.39969\n",
      "[245]\ttrain-rmse:0.38386\tval-rmse:0.39940\n",
      "[246]\ttrain-rmse:0.38350\tval-rmse:0.39911\n",
      "[247]\ttrain-rmse:0.38313\tval-rmse:0.39881\n",
      "[248]\ttrain-rmse:0.38275\tval-rmse:0.39848\n",
      "[249]\ttrain-rmse:0.38238\tval-rmse:0.39819\n",
      "[250]\ttrain-rmse:0.38202\tval-rmse:0.39789\n",
      "[251]\ttrain-rmse:0.38168\tval-rmse:0.39759\n",
      "[252]\ttrain-rmse:0.38134\tval-rmse:0.39735\n",
      "[253]\ttrain-rmse:0.38100\tval-rmse:0.39707\n",
      "[254]\ttrain-rmse:0.38066\tval-rmse:0.39676\n",
      "[255]\ttrain-rmse:0.38030\tval-rmse:0.39650\n",
      "[256]\ttrain-rmse:0.37995\tval-rmse:0.39623\n",
      "[257]\ttrain-rmse:0.37962\tval-rmse:0.39596\n",
      "[258]\ttrain-rmse:0.37930\tval-rmse:0.39572\n",
      "[259]\ttrain-rmse:0.37895\tval-rmse:0.39541\n",
      "[260]\ttrain-rmse:0.37863\tval-rmse:0.39513\n",
      "[261]\ttrain-rmse:0.37828\tval-rmse:0.39486\n",
      "[262]\ttrain-rmse:0.37794\tval-rmse:0.39460\n",
      "[263]\ttrain-rmse:0.37761\tval-rmse:0.39430\n",
      "[264]\ttrain-rmse:0.37729\tval-rmse:0.39403\n",
      "[265]\ttrain-rmse:0.37693\tval-rmse:0.39374\n",
      "[266]\ttrain-rmse:0.37661\tval-rmse:0.39346\n",
      "[267]\ttrain-rmse:0.37631\tval-rmse:0.39320\n",
      "[268]\ttrain-rmse:0.37594\tval-rmse:0.39289\n",
      "[269]\ttrain-rmse:0.37562\tval-rmse:0.39264\n",
      "[270]\ttrain-rmse:0.37529\tval-rmse:0.39236\n",
      "[271]\ttrain-rmse:0.37497\tval-rmse:0.39205\n",
      "[272]\ttrain-rmse:0.37466\tval-rmse:0.39178\n",
      "[273]\ttrain-rmse:0.37434\tval-rmse:0.39155\n",
      "[274]\ttrain-rmse:0.37400\tval-rmse:0.39127\n",
      "[275]\ttrain-rmse:0.37367\tval-rmse:0.39102\n",
      "[276]\ttrain-rmse:0.37335\tval-rmse:0.39074\n",
      "[277]\ttrain-rmse:0.37305\tval-rmse:0.39048\n",
      "[278]\ttrain-rmse:0.37273\tval-rmse:0.39020\n",
      "[279]\ttrain-rmse:0.37243\tval-rmse:0.38998\n",
      "[280]\ttrain-rmse:0.37214\tval-rmse:0.38974\n",
      "[281]\ttrain-rmse:0.37182\tval-rmse:0.38948\n",
      "[282]\ttrain-rmse:0.37148\tval-rmse:0.38920\n",
      "[283]\ttrain-rmse:0.37117\tval-rmse:0.38895\n",
      "[284]\ttrain-rmse:0.37087\tval-rmse:0.38868\n",
      "[285]\ttrain-rmse:0.37052\tval-rmse:0.38841\n",
      "[286]\ttrain-rmse:0.37020\tval-rmse:0.38816\n",
      "[287]\ttrain-rmse:0.36989\tval-rmse:0.38791\n",
      "[288]\ttrain-rmse:0.36959\tval-rmse:0.38766\n",
      "[289]\ttrain-rmse:0.36926\tval-rmse:0.38739\n",
      "[290]\ttrain-rmse:0.36899\tval-rmse:0.38715\n",
      "[291]\ttrain-rmse:0.36865\tval-rmse:0.38687\n",
      "[292]\ttrain-rmse:0.36831\tval-rmse:0.38662\n",
      "[293]\ttrain-rmse:0.36801\tval-rmse:0.38638\n",
      "[294]\ttrain-rmse:0.36774\tval-rmse:0.38614\n",
      "[295]\ttrain-rmse:0.36740\tval-rmse:0.38584\n",
      "[296]\ttrain-rmse:0.36710\tval-rmse:0.38560\n",
      "[297]\ttrain-rmse:0.36677\tval-rmse:0.38533\n",
      "[298]\ttrain-rmse:0.36643\tval-rmse:0.38504\n",
      "[299]\ttrain-rmse:0.36614\tval-rmse:0.38482\n",
      "[300]\ttrain-rmse:0.36582\tval-rmse:0.38457\n",
      "[301]\ttrain-rmse:0.36550\tval-rmse:0.38431\n",
      "[302]\ttrain-rmse:0.36520\tval-rmse:0.38405\n",
      "[303]\ttrain-rmse:0.36490\tval-rmse:0.38382\n",
      "[304]\ttrain-rmse:0.36459\tval-rmse:0.38355\n",
      "[305]\ttrain-rmse:0.36429\tval-rmse:0.38334\n",
      "[306]\ttrain-rmse:0.36400\tval-rmse:0.38307\n",
      "[307]\ttrain-rmse:0.36369\tval-rmse:0.38287\n",
      "[308]\ttrain-rmse:0.36339\tval-rmse:0.38259\n",
      "[309]\ttrain-rmse:0.36307\tval-rmse:0.38234\n",
      "[310]\ttrain-rmse:0.36276\tval-rmse:0.38211\n",
      "[311]\ttrain-rmse:0.36242\tval-rmse:0.38187\n",
      "[312]\ttrain-rmse:0.36211\tval-rmse:0.38164\n",
      "[313]\ttrain-rmse:0.36179\tval-rmse:0.38138\n",
      "[314]\ttrain-rmse:0.36149\tval-rmse:0.38112\n",
      "[315]\ttrain-rmse:0.36116\tval-rmse:0.38087\n",
      "[316]\ttrain-rmse:0.36086\tval-rmse:0.38062\n",
      "[317]\ttrain-rmse:0.36056\tval-rmse:0.38036\n",
      "[318]\ttrain-rmse:0.36025\tval-rmse:0.38012\n",
      "[319]\ttrain-rmse:0.35996\tval-rmse:0.37991\n",
      "[320]\ttrain-rmse:0.35965\tval-rmse:0.37963\n",
      "[321]\ttrain-rmse:0.35938\tval-rmse:0.37942\n",
      "[322]\ttrain-rmse:0.35908\tval-rmse:0.37919\n",
      "[323]\ttrain-rmse:0.35879\tval-rmse:0.37896\n",
      "[324]\ttrain-rmse:0.35847\tval-rmse:0.37873\n",
      "[325]\ttrain-rmse:0.35819\tval-rmse:0.37849\n",
      "[326]\ttrain-rmse:0.35791\tval-rmse:0.37826\n",
      "[327]\ttrain-rmse:0.35761\tval-rmse:0.37800\n",
      "[328]\ttrain-rmse:0.35733\tval-rmse:0.37776\n",
      "[329]\ttrain-rmse:0.35703\tval-rmse:0.37754\n",
      "[330]\ttrain-rmse:0.35675\tval-rmse:0.37730\n",
      "[331]\ttrain-rmse:0.35647\tval-rmse:0.37708\n",
      "[332]\ttrain-rmse:0.35615\tval-rmse:0.37685\n",
      "[333]\ttrain-rmse:0.35585\tval-rmse:0.37660\n",
      "[334]\ttrain-rmse:0.35557\tval-rmse:0.37637\n",
      "[335]\ttrain-rmse:0.35530\tval-rmse:0.37616\n",
      "[336]\ttrain-rmse:0.35500\tval-rmse:0.37595\n",
      "[337]\ttrain-rmse:0.35468\tval-rmse:0.37570\n",
      "[338]\ttrain-rmse:0.35438\tval-rmse:0.37548\n",
      "[339]\ttrain-rmse:0.35410\tval-rmse:0.37522\n",
      "[340]\ttrain-rmse:0.35380\tval-rmse:0.37499\n",
      "[341]\ttrain-rmse:0.35351\tval-rmse:0.37476\n",
      "[342]\ttrain-rmse:0.35320\tval-rmse:0.37453\n",
      "[343]\ttrain-rmse:0.35294\tval-rmse:0.37431\n",
      "[344]\ttrain-rmse:0.35267\tval-rmse:0.37410\n",
      "[345]\ttrain-rmse:0.35239\tval-rmse:0.37388\n",
      "[346]\ttrain-rmse:0.35212\tval-rmse:0.37368\n",
      "[347]\ttrain-rmse:0.35182\tval-rmse:0.37346\n",
      "[348]\ttrain-rmse:0.35154\tval-rmse:0.37322\n",
      "[349]\ttrain-rmse:0.35126\tval-rmse:0.37302\n",
      "[350]\ttrain-rmse:0.35097\tval-rmse:0.37279\n",
      "[351]\ttrain-rmse:0.35066\tval-rmse:0.37258\n",
      "[352]\ttrain-rmse:0.35040\tval-rmse:0.37236\n",
      "[353]\ttrain-rmse:0.35010\tval-rmse:0.37211\n",
      "[354]\ttrain-rmse:0.34981\tval-rmse:0.37187\n",
      "[355]\ttrain-rmse:0.34955\tval-rmse:0.37166\n",
      "[356]\ttrain-rmse:0.34927\tval-rmse:0.37146\n",
      "[357]\ttrain-rmse:0.34900\tval-rmse:0.37122\n",
      "[358]\ttrain-rmse:0.34871\tval-rmse:0.37100\n",
      "[359]\ttrain-rmse:0.34841\tval-rmse:0.37075\n",
      "[360]\ttrain-rmse:0.34813\tval-rmse:0.37053\n",
      "[361]\ttrain-rmse:0.34786\tval-rmse:0.37031\n",
      "[362]\ttrain-rmse:0.34758\tval-rmse:0.37011\n",
      "[363]\ttrain-rmse:0.34730\tval-rmse:0.36991\n",
      "[364]\ttrain-rmse:0.34703\tval-rmse:0.36967\n",
      "[365]\ttrain-rmse:0.34679\tval-rmse:0.36947\n",
      "[366]\ttrain-rmse:0.34653\tval-rmse:0.36926\n",
      "[367]\ttrain-rmse:0.34628\tval-rmse:0.36902\n",
      "[368]\ttrain-rmse:0.34599\tval-rmse:0.36881\n",
      "[369]\ttrain-rmse:0.34571\tval-rmse:0.36860\n",
      "[370]\ttrain-rmse:0.34544\tval-rmse:0.36840\n",
      "[371]\ttrain-rmse:0.34517\tval-rmse:0.36821\n",
      "[372]\ttrain-rmse:0.34493\tval-rmse:0.36803\n",
      "[373]\ttrain-rmse:0.34469\tval-rmse:0.36784\n",
      "[374]\ttrain-rmse:0.34443\tval-rmse:0.36764\n",
      "[375]\ttrain-rmse:0.34416\tval-rmse:0.36743\n",
      "[376]\ttrain-rmse:0.34389\tval-rmse:0.36723\n",
      "[377]\ttrain-rmse:0.34361\tval-rmse:0.36702\n",
      "[378]\ttrain-rmse:0.34333\tval-rmse:0.36679\n",
      "[379]\ttrain-rmse:0.34307\tval-rmse:0.36656\n",
      "[380]\ttrain-rmse:0.34281\tval-rmse:0.36638\n",
      "[381]\ttrain-rmse:0.34254\tval-rmse:0.36616\n",
      "[382]\ttrain-rmse:0.34227\tval-rmse:0.36598\n",
      "[383]\ttrain-rmse:0.34204\tval-rmse:0.36582\n",
      "[384]\ttrain-rmse:0.34177\tval-rmse:0.36561\n",
      "[385]\ttrain-rmse:0.34152\tval-rmse:0.36542\n",
      "[386]\ttrain-rmse:0.34123\tval-rmse:0.36522\n",
      "[387]\ttrain-rmse:0.34097\tval-rmse:0.36503\n",
      "[388]\ttrain-rmse:0.34072\tval-rmse:0.36483\n",
      "[389]\ttrain-rmse:0.34046\tval-rmse:0.36466\n",
      "[390]\ttrain-rmse:0.34020\tval-rmse:0.36444\n",
      "[391]\ttrain-rmse:0.33996\tval-rmse:0.36427\n",
      "[392]\ttrain-rmse:0.33971\tval-rmse:0.36408\n",
      "[393]\ttrain-rmse:0.33945\tval-rmse:0.36388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394]\ttrain-rmse:0.33921\tval-rmse:0.36370\n",
      "[395]\ttrain-rmse:0.33898\tval-rmse:0.36350\n",
      "[396]\ttrain-rmse:0.33871\tval-rmse:0.36328\n",
      "[397]\ttrain-rmse:0.33850\tval-rmse:0.36309\n",
      "[398]\ttrain-rmse:0.33824\tval-rmse:0.36289\n",
      "[399]\ttrain-rmse:0.33797\tval-rmse:0.36268\n",
      "[400]\ttrain-rmse:0.33772\tval-rmse:0.36247\n",
      "[401]\ttrain-rmse:0.33747\tval-rmse:0.36227\n",
      "[402]\ttrain-rmse:0.33723\tval-rmse:0.36210\n",
      "[403]\ttrain-rmse:0.33698\tval-rmse:0.36189\n",
      "[404]\ttrain-rmse:0.33677\tval-rmse:0.36172\n",
      "[405]\ttrain-rmse:0.33653\tval-rmse:0.36154\n",
      "[406]\ttrain-rmse:0.33630\tval-rmse:0.36138\n",
      "[407]\ttrain-rmse:0.33603\tval-rmse:0.36117\n",
      "[408]\ttrain-rmse:0.33578\tval-rmse:0.36098\n",
      "[409]\ttrain-rmse:0.33553\tval-rmse:0.36081\n",
      "[410]\ttrain-rmse:0.33527\tval-rmse:0.36061\n",
      "[411]\ttrain-rmse:0.33501\tval-rmse:0.36043\n",
      "[412]\ttrain-rmse:0.33475\tval-rmse:0.36024\n",
      "[413]\ttrain-rmse:0.33448\tval-rmse:0.36004\n",
      "[414]\ttrain-rmse:0.33421\tval-rmse:0.35984\n",
      "[415]\ttrain-rmse:0.33397\tval-rmse:0.35966\n",
      "[416]\ttrain-rmse:0.33373\tval-rmse:0.35946\n",
      "[417]\ttrain-rmse:0.33350\tval-rmse:0.35926\n",
      "[418]\ttrain-rmse:0.33325\tval-rmse:0.35906\n",
      "[419]\ttrain-rmse:0.33299\tval-rmse:0.35888\n",
      "[420]\ttrain-rmse:0.33274\tval-rmse:0.35870\n",
      "[421]\ttrain-rmse:0.33252\tval-rmse:0.35853\n",
      "[422]\ttrain-rmse:0.33226\tval-rmse:0.35834\n",
      "[423]\ttrain-rmse:0.33202\tval-rmse:0.35815\n",
      "[424]\ttrain-rmse:0.33179\tval-rmse:0.35796\n",
      "[425]\ttrain-rmse:0.33157\tval-rmse:0.35780\n",
      "[426]\ttrain-rmse:0.33133\tval-rmse:0.35761\n",
      "[427]\ttrain-rmse:0.33108\tval-rmse:0.35747\n",
      "[428]\ttrain-rmse:0.33084\tval-rmse:0.35729\n",
      "[429]\ttrain-rmse:0.33062\tval-rmse:0.35713\n",
      "[430]\ttrain-rmse:0.33038\tval-rmse:0.35694\n",
      "[431]\ttrain-rmse:0.33015\tval-rmse:0.35677\n",
      "[432]\ttrain-rmse:0.32991\tval-rmse:0.35657\n",
      "[433]\ttrain-rmse:0.32965\tval-rmse:0.35639\n",
      "[434]\ttrain-rmse:0.32940\tval-rmse:0.35621\n",
      "[435]\ttrain-rmse:0.32917\tval-rmse:0.35603\n",
      "[436]\ttrain-rmse:0.32895\tval-rmse:0.35585\n",
      "[437]\ttrain-rmse:0.32873\tval-rmse:0.35569\n",
      "[438]\ttrain-rmse:0.32850\tval-rmse:0.35551\n",
      "[439]\ttrain-rmse:0.32826\tval-rmse:0.35532\n",
      "[440]\ttrain-rmse:0.32804\tval-rmse:0.35514\n",
      "[441]\ttrain-rmse:0.32784\tval-rmse:0.35498\n",
      "[442]\ttrain-rmse:0.32760\tval-rmse:0.35483\n",
      "[443]\ttrain-rmse:0.32738\tval-rmse:0.35469\n",
      "[444]\ttrain-rmse:0.32714\tval-rmse:0.35454\n",
      "[445]\ttrain-rmse:0.32692\tval-rmse:0.35437\n",
      "[446]\ttrain-rmse:0.32669\tval-rmse:0.35417\n",
      "[447]\ttrain-rmse:0.32648\tval-rmse:0.35401\n",
      "[448]\ttrain-rmse:0.32624\tval-rmse:0.35382\n",
      "[449]\ttrain-rmse:0.32600\tval-rmse:0.35364\n",
      "[450]\ttrain-rmse:0.32577\tval-rmse:0.35347\n",
      "[451]\ttrain-rmse:0.32556\tval-rmse:0.35330\n",
      "[452]\ttrain-rmse:0.32532\tval-rmse:0.35312\n",
      "[453]\ttrain-rmse:0.32511\tval-rmse:0.35297\n",
      "[454]\ttrain-rmse:0.32489\tval-rmse:0.35279\n",
      "[455]\ttrain-rmse:0.32466\tval-rmse:0.35263\n",
      "[456]\ttrain-rmse:0.32443\tval-rmse:0.35245\n",
      "[457]\ttrain-rmse:0.32418\tval-rmse:0.35227\n",
      "[458]\ttrain-rmse:0.32394\tval-rmse:0.35208\n",
      "[459]\ttrain-rmse:0.32370\tval-rmse:0.35191\n",
      "[460]\ttrain-rmse:0.32349\tval-rmse:0.35176\n",
      "[461]\ttrain-rmse:0.32328\tval-rmse:0.35162\n",
      "[462]\ttrain-rmse:0.32306\tval-rmse:0.35145\n",
      "[463]\ttrain-rmse:0.32286\tval-rmse:0.35130\n",
      "[464]\ttrain-rmse:0.32265\tval-rmse:0.35116\n",
      "[465]\ttrain-rmse:0.32245\tval-rmse:0.35099\n",
      "[466]\ttrain-rmse:0.32223\tval-rmse:0.35082\n",
      "[467]\ttrain-rmse:0.32201\tval-rmse:0.35065\n",
      "[468]\ttrain-rmse:0.32178\tval-rmse:0.35049\n",
      "[469]\ttrain-rmse:0.32154\tval-rmse:0.35033\n",
      "[470]\ttrain-rmse:0.32132\tval-rmse:0.35017\n",
      "[471]\ttrain-rmse:0.32111\tval-rmse:0.35000\n",
      "[472]\ttrain-rmse:0.32091\tval-rmse:0.34986\n",
      "[473]\ttrain-rmse:0.32070\tval-rmse:0.34971\n",
      "[474]\ttrain-rmse:0.32049\tval-rmse:0.34954\n",
      "[475]\ttrain-rmse:0.32027\tval-rmse:0.34938\n",
      "[476]\ttrain-rmse:0.32004\tval-rmse:0.34921\n",
      "[477]\ttrain-rmse:0.31983\tval-rmse:0.34906\n",
      "[478]\ttrain-rmse:0.31962\tval-rmse:0.34889\n",
      "[479]\ttrain-rmse:0.31941\tval-rmse:0.34873\n",
      "[480]\ttrain-rmse:0.31919\tval-rmse:0.34856\n",
      "[481]\ttrain-rmse:0.31899\tval-rmse:0.34843\n",
      "[482]\ttrain-rmse:0.31880\tval-rmse:0.34830\n",
      "[483]\ttrain-rmse:0.31859\tval-rmse:0.34814\n",
      "[484]\ttrain-rmse:0.31837\tval-rmse:0.34796\n",
      "[485]\ttrain-rmse:0.31814\tval-rmse:0.34782\n",
      "[486]\ttrain-rmse:0.31792\tval-rmse:0.34766\n",
      "[487]\ttrain-rmse:0.31773\tval-rmse:0.34751\n",
      "[488]\ttrain-rmse:0.31752\tval-rmse:0.34735\n",
      "[489]\ttrain-rmse:0.31729\tval-rmse:0.34717\n",
      "[490]\ttrain-rmse:0.31709\tval-rmse:0.34700\n",
      "[491]\ttrain-rmse:0.31688\tval-rmse:0.34683\n",
      "[492]\ttrain-rmse:0.31668\tval-rmse:0.34669\n",
      "[493]\ttrain-rmse:0.31648\tval-rmse:0.34655\n",
      "[494]\ttrain-rmse:0.31627\tval-rmse:0.34641\n",
      "[495]\ttrain-rmse:0.31606\tval-rmse:0.34626\n",
      "[496]\ttrain-rmse:0.31583\tval-rmse:0.34612\n",
      "[497]\ttrain-rmse:0.31565\tval-rmse:0.34599\n",
      "[498]\ttrain-rmse:0.31545\tval-rmse:0.34585\n",
      "[499]\ttrain-rmse:0.31525\tval-rmse:0.34571\n",
      "best iteration 499\n",
      "Accuracy: 91.93%\n",
      "Error Rate: 8.07%\n",
      "xgboost success! \n",
      " cost time: 2.7956156730651855 (s)......\n"
     ]
    }
   ],
   "source": [
    "#训练模型并保存  \n",
    "# early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练  \n",
    "model = xgb.train(  \n",
    "    plst,  \n",
    "    xgb_train,  \n",
    "    num_rounds,  \n",
    "    watchlist,  \n",
    "    early_stopping_rounds=100,  \n",
    ")  \n",
    "#model.save_model('./model/xgb.model') # 用于存储训练出的模型  \n",
    "print(\"best iteration\", model.best_iteration)  \n",
    "  \n",
    "y_pred = model.predict(xgb_test)  \n",
    "  \n",
    "# 计算预测准确率  \n",
    "predicted_correctly = sum(1 for i in range(len(y_pred)) if int(y_pred[i] > 0.5) == y_test[i])  \n",
    "accuracy = predicted_correctly / float(len(y_pred))  \n",
    "print('Accuracy: %.2f%%' % (accuracy * 100.0))  \n",
    "  \n",
    "# 计算误差率  \n",
    "error_rate = sum(1 for i in range(len(y_pred)) if int(y_pred[i] > 0.5) != y_test[i]) / float(len(y_pred))  \n",
    "print('Error Rate: %.2f%%' % (error_rate * 100.0))  \n",
    "  \n",
    "# 输出运行时长  \n",
    "cost_time = time.time() - start_time  \n",
    "print(\"xgboost success!\", '\\n', \"cost time:\", cost_time, \"(s)......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee89f1",
   "metadata": {},
   "source": [
    "### 2.使用scikit-learn接口\n",
    "会改变的函数名是：\n",
    "\n",
    "eta -> learning_rate\n",
    "\n",
    "lambda -> reg_lambda\n",
    "\n",
    "alpha -> reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee9b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    #     silent=0,  #设置成1则没有运行信息输出，最好是设置为0.是否在运行升级时打印消息。\n",
    "    #nthread=4,# cpu 线程数 默认最大\n",
    "    learning_rate=0.3,  # 如同学习率\n",
    "    min_child_weight=1,\n",
    "    # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "    #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "    #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "    max_depth=6,  # 构建树的深度，越大越容易过拟合\n",
    "    gamma=0,  # 树的叶子节点上作进一步分区所需的最小损失减少,越大越保守，一般0.1、0.2这样子。\n",
    "    subsample=1,  # 随机采样训练样本 训练实例的子采样比\n",
    "    max_delta_step=0,  #最大增量步长，我们允许每个树的权重估计。\n",
    "    colsample_bytree=1,  # 生成树时进行的列采样 \n",
    "    reg_lambda=1,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    #reg_alpha=0, # L1 正则项参数\n",
    "    #scale_pos_weight=1, #如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。平衡正负权重\n",
    "    #objective= 'multi:softmax', #多分类的问题 指定学习任务和相应的学习目标\n",
    "    #num_class=10, # 类别数，多分类与 multisoftmax 并用\n",
    "    n_estimators=100,  #树的个数\n",
    "    seed=1000  #随机种子\n",
    "    #eval_metric= 'auc'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6196fe2",
   "metadata": {},
   "source": [
    "## LIghtGBM的使用\n",
    "### 1.原生接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fa87f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.500778\n",
      "Save model...\n",
      "Start predicting...\n",
      "error=0.081000\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 加载你的数据\n",
    "# print('Load data...')\n",
    "# df_train = pd.read_csv('../regression/regression.train', header=None, sep='\\t')\n",
    "# df_test = pd.read_csv('../regression/regression.test', header=None, sep='\\t')\n",
    "#\n",
    "# y_train = df_train[0].values\n",
    "# y_test = df_test[0].values\n",
    "# X_train = df_train.drop(0, axis=1).values\n",
    "# X_test = df_test.drop(0, axis=1).values\n",
    "\n",
    "# 创建成lgb特征的数据集格式\n",
    "lgb_train = lgb.Dataset(X_train, y_train)  # 将数据保存到LightGBM二进制文件将使加载更快\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)  # 创建验证数据\n",
    "\n",
    "# 将参数写成字典下形式\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression',  # 目标函数\n",
    "    'metric': {'l2', 'auc'},  # 评估函数\n",
    "    'num_leaves': 31,  # 叶子节点数\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'feature_fraction': 0.9,  # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8,  # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1  # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# 训练 cv and train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                valid_sets=lgb_eval)  # 训练数据需要参数列表和数据集\n",
    "\n",
    "print('Save model...')\n",
    "\n",
    "gbm.save_model('model.txt')  # 训练后保存模型到文件\n",
    "\n",
    "print('Start predicting...')\n",
    "# 预测数据集\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration\n",
    "                     )  #如果在训练期间启用了早期停止，可以通过best_iteration方式从最佳迭代中获得预测\n",
    "# 评估模型\n",
    "print('error=%f' %\n",
    "      (sum(1\n",
    "           for i in range(len(y_pred)) if int(y_pred[i] > 0.5) != y_test[i]) /\n",
    "       float(len(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca2e65",
   "metadata": {},
   "source": [
    "## 2.scikit-learn接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7140ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4507, number of negative: 4493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500778 -> initscore=0.003111\n",
      "[LightGBM] [Info] Start training from score 0.003111\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4507, number of negative: 4493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500778 -> initscore=0.003111\n",
      "[LightGBM] [Info] Start training from score 0.003111\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Accuracy : 0.9377\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "    boosting_type='gbdt',  # 提升树的类型 gbdt,dart,goss,rf\n",
    "    num_leaves=31,  #树的最大叶子数，对比xgboost一般为2^(max_depth)\n",
    "    max_depth=-1,  #最大树的深度\n",
    "    learning_rate=0.1,  #学习率\n",
    "    n_estimators=100,  # 拟合的树的棵树，相当于训练轮数\n",
    "    subsample_for_bin=200000,\n",
    "    objective=None,\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.0,  # 最小分割增益\n",
    "    min_child_weight=0.001,  # 分支结点的最小权重\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,  # 训练样本采样率 行\n",
    "    subsample_freq=0,  # 子样本频率\n",
    "    colsample_bytree=1.0,  # 训练特征采样率 列\n",
    "    reg_alpha=0.0,  # L1正则化系数\n",
    "    reg_lambda=0.0,  # L2正则化系数\n",
    "    random_state=None,\n",
    "    n_jobs=-1,\n",
    "    silent=True,\n",
    ")\n",
    "clf.fit(X_train, y_train, eval_metric='auc')\n",
    "#设置验证集合 verbose=False不打印过程\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f1ef3",
   "metadata": {},
   "source": [
    "## 参考\n",
    "1.https://xgboost.readthedocs.io/\n",
    "\n",
    "2.https://lightgbm.readthedocs.io/\n",
    "\n",
    "3.https://blog.csdn.net/q383700092/article/details/53763328?locationNum=9&fps=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
